{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-6 Project PML\n",
    "## Hand written Digit recogonition using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Members\n",
    "#### Vishnu Radhakrishnan - [CB.EN.U4AIE20074]\n",
    "#### Visweswaran M - [CB.EN.U4AIE20075]\n",
    "#### Menta Sai Akshay - [CB.EN.U4AIE20040]\n",
    "#### Krishnan KM - [CB.EN.U4AIE20031]\n",
    "#### Thushit Kumar R - [CB.EN.U4AIE20072]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SVM as Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def KernelFunction(X1,X2,sigma):\n",
    "    # np.exp((-1)*(np.linalg.norm(X1-X2))/(2*(sigma**2)))  ## RBF Kernel Function\n",
    "    # np.dot(X1,X2)                                        ## Liner Kernel function\n",
    "    return np.exp((-1)*(np.linalg.norm(X1-X2))/(2*(sigma**2)))\n",
    "\n",
    "def KernelMatrix(Data,Y,NoOfDataSets,si):\n",
    "    K = np.ones((NoOfDataSets,NoOfDataSets))\n",
    "    for i in range(0,NoOfDataSets):\n",
    "        for j in range(0,NoOfDataSets):\n",
    "            K[i,j] = Y[i,0]*Y[j,0]*KernelFunction(Data[i,0:],Data[j,0:],si)\n",
    "    return K\n",
    "\n",
    "def SVMPara(Data,Y,C,NoOfDataSets,sigma=0):\n",
    "    UpperMatrix = np.concatenate((np.array([[0]]),(-1)*Y.transpose()),axis = 1)\n",
    "    LowerMatrix = np.concatenate((Y,KernelMatrix(Data,Y,NoOfDataSets,sigma) + ((1/C)*np.eye(NoOfDataSets))),axis = 1)\n",
    "    A = np.concatenate((UpperMatrix,LowerMatrix),axis = 0)\n",
    "    B = (np.concatenate((np.array([[0]]),np.array([np.ones(NoOfDataSets)])),axis = 1)).transpose()\n",
    "    return np.linalg.inv(A)@B\n",
    "\n",
    "def Weight(w,X_train,Y_train):\n",
    "    return np.concatenate((np.array([[w[0,0]]]),np.transpose(np.array([np.sum(np.multiply(np.multiply(Y_train,w[1:]),X_train),axis=0)]))),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:100,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:10,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:10,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:10,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:10,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:10,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:10,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:10,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:10,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 10, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 10, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 10, Accuracy: 0.6491228070175439\n"
     ]
    }
   ],
   "source": [
    "Y_0 = np.array([np.concatenate(((1)*np.ones(Dataset_0.shape[0]),np.concatenate(((-1)*np.ones(Dataset_1.shape[0]),np.concatenate(((-1)*np.ones(Dataset_2.shape[0]),np.concatenate(((-1)*np.ones(Dataset_3.shape[0]),np.concatenate(((-1)*np.ones(Dataset_4.shape[0]),np.concatenate(((-1)*np.ones(Dataset_5.shape[0]),np.concatenate(((-1)*np.ones(Dataset_6.shape[0]),np.concatenate(((-1)*np.ones(Dataset_7.shape[0]),np.concatenate(((-1)*np.ones(Dataset_8.shape[0]),(-1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:10,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:100,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:10,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:10,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:10,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:10,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:10,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:10,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:10,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.8596491228070176\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.8596491228070176\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.8596491228070176\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.8596491228070176\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.8596491228070176\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.8596491228070176\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.8596491228070176\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.8596491228070176\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.8596491228070176\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.8596491228070176\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.8596491228070176\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.8596491228070176\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.8596491228070176\n",
      "C: 1, Sigma: 1, Accuracy: 0.8596491228070176\n",
      "C: 1, Sigma: 10, Accuracy: 0.8421052631578947\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.8596491228070176\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.8596491228070176\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.8596491228070176\n",
      "C: 10, Sigma: 1, Accuracy: 0.8596491228070176\n",
      "C: 10, Sigma: 10, Accuracy: 0.8421052631578947\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.8596491228070176\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.8596491228070176\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.8596491228070176\n",
      "C: 100, Sigma: 1, Accuracy: 0.8596491228070176\n",
      "C: 100, Sigma: 10, Accuracy: 0.8245614035087719\n"
     ]
    }
   ],
   "source": [
    "Y_1 = np.array([np.concatenate(((-1)*np.ones(Dataset_0.shape[0]),np.concatenate(((1)*np.ones(Dataset_1.shape[0]),np.concatenate(((-1)*np.ones(Dataset_2.shape[0]),np.concatenate(((-1)*np.ones(Dataset_3.shape[0]),np.concatenate(((-1)*np.ones(Dataset_4.shape[0]),np.concatenate(((-1)*np.ones(Dataset_5.shape[0]),np.concatenate(((-1)*np.ones(Dataset_6.shape[0]),np.concatenate(((-1)*np.ones(Dataset_7.shape[0]),np.concatenate(((-1)*np.ones(Dataset_8.shape[0]),(-1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:10,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:10,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:100,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:10,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:10,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:10,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:10,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:10,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:10,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 10, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 10, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 10, Accuracy: 0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "Y_2 = np.array([np.concatenate(((-1)*np.ones(Dataset_0.shape[0]),np.concatenate(((-1)*np.ones(Dataset_1.shape[0]),np.concatenate(((1)*np.ones(Dataset_2.shape[0]),np.concatenate(((-1)*np.ones(Dataset_3.shape[0]),np.concatenate(((-1)*np.ones(Dataset_4.shape[0]),np.concatenate(((-1)*np.ones(Dataset_5.shape[0]),np.concatenate(((-1)*np.ones(Dataset_6.shape[0]),np.concatenate(((-1)*np.ones(Dataset_7.shape[0]),np.concatenate(((-1)*np.ones(Dataset_8.shape[0]),(-1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:10,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:10,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:100,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:10,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:10,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:10,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:10,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:10,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:10,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 1, Sigma: 10, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 10, Sigma: 10, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 1, Accuracy: 0.7719298245614035\n",
      "C: 100, Sigma: 10, Accuracy: 0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "Y_3 = np.array([np.concatenate(((-1)*np.ones(Dataset_0.shape[0]),np.concatenate(((-1)*np.ones(Dataset_1.shape[0]),np.concatenate(((-1)*np.ones(Dataset_2.shape[0]),np.concatenate(((1)*np.ones(Dataset_3.shape[0]),np.concatenate(((-1)*np.ones(Dataset_4.shape[0]),np.concatenate(((-1)*np.ones(Dataset_5.shape[0]),np.concatenate(((-1)*np.ones(Dataset_6.shape[0]),np.concatenate(((-1)*np.ones(Dataset_7.shape[0]),np.concatenate(((-1)*np.ones(Dataset_8.shape[0]),(-1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGIT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:10,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:10,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:10,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:100,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:10,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:10,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:10,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:10,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:10,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.5263157894736842\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.5263157894736842\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.5263157894736842\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.5263157894736842\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.5263157894736842\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.5263157894736842\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.5263157894736842\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.5263157894736842\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.5263157894736842\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.5263157894736842\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.5263157894736842\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.5263157894736842\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.5263157894736842\n",
      "C: 1, Sigma: 1, Accuracy: 0.5263157894736842\n",
      "C: 1, Sigma: 10, Accuracy: 0.5263157894736842\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.5263157894736842\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.5263157894736842\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.5263157894736842\n",
      "C: 10, Sigma: 1, Accuracy: 0.5263157894736842\n",
      "C: 10, Sigma: 10, Accuracy: 0.5263157894736842\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.5263157894736842\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.5263157894736842\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.5263157894736842\n",
      "C: 100, Sigma: 1, Accuracy: 0.5263157894736842\n",
      "C: 100, Sigma: 10, Accuracy: 0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "Y_4 = np.array([np.concatenate(((-1)*np.ones(Dataset_0.shape[0]),np.concatenate(((-1)*np.ones(Dataset_1.shape[0]),np.concatenate(((-1)*np.ones(Dataset_2.shape[0]),np.concatenate(((-1)*np.ones(Dataset_3.shape[0]),np.concatenate(((1)*np.ones(Dataset_4.shape[0]),np.concatenate(((-1)*np.ones(Dataset_5.shape[0]),np.concatenate(((-1)*np.ones(Dataset_6.shape[0]),np.concatenate(((-1)*np.ones(Dataset_7.shape[0]),np.concatenate(((-1)*np.ones(Dataset_8.shape[0]),(-1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:10,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:10,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:10,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:10,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:100,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:10,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:10,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:10,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:10,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.631578947368421\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.631578947368421\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.631578947368421\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.631578947368421\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.631578947368421\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.631578947368421\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.631578947368421\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.631578947368421\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.631578947368421\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.631578947368421\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.631578947368421\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.631578947368421\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.631578947368421\n",
      "C: 1, Sigma: 1, Accuracy: 0.631578947368421\n",
      "C: 1, Sigma: 10, Accuracy: 0.631578947368421\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.631578947368421\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.631578947368421\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.631578947368421\n",
      "C: 10, Sigma: 1, Accuracy: 0.631578947368421\n",
      "C: 10, Sigma: 10, Accuracy: 0.6140350877192983\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.631578947368421\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.631578947368421\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.631578947368421\n",
      "C: 100, Sigma: 1, Accuracy: 0.631578947368421\n",
      "C: 100, Sigma: 10, Accuracy: 0.6140350877192983\n"
     ]
    }
   ],
   "source": [
    "Y_5 = np.array([np.concatenate(((-1)*np.ones(Dataset_0.shape[0]),np.concatenate(((-1)*np.ones(Dataset_1.shape[0]),np.concatenate(((-1)*np.ones(Dataset_2.shape[0]),np.concatenate(((-1)*np.ones(Dataset_3.shape[0]),np.concatenate(((-1)*np.ones(Dataset_4.shape[0]),np.concatenate(((1)*np.ones(Dataset_5.shape[0]),np.concatenate(((-1)*np.ones(Dataset_6.shape[0]),np.concatenate(((-1)*np.ones(Dataset_7.shape[0]),np.concatenate(((-1)*np.ones(Dataset_8.shape[0]),(-1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGIT 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:10,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:10,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:10,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:10,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:10,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:100,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:10,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:10,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:10,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.49122807017543857\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.49122807017543857\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.49122807017543857\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.49122807017543857\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.49122807017543857\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.49122807017543857\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.49122807017543857\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.49122807017543857\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.49122807017543857\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.49122807017543857\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.49122807017543857\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.49122807017543857\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.49122807017543857\n",
      "C: 1, Sigma: 1, Accuracy: 0.49122807017543857\n",
      "C: 1, Sigma: 10, Accuracy: 0.49122807017543857\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.49122807017543857\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.49122807017543857\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.49122807017543857\n",
      "C: 10, Sigma: 1, Accuracy: 0.49122807017543857\n",
      "C: 10, Sigma: 10, Accuracy: 0.49122807017543857\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.49122807017543857\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.49122807017543857\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.49122807017543857\n",
      "C: 100, Sigma: 1, Accuracy: 0.49122807017543857\n",
      "C: 100, Sigma: 10, Accuracy: 0.49122807017543857\n"
     ]
    }
   ],
   "source": [
    "Y_6 = np.array([np.concatenate(((-1)*np.ones(Dataset_0.shape[0]),np.concatenate(((-1)*np.ones(Dataset_1.shape[0]),np.concatenate(((-1)*np.ones(Dataset_2.shape[0]),np.concatenate(((-1)*np.ones(Dataset_3.shape[0]),np.concatenate(((-1)*np.ones(Dataset_4.shape[0]),np.concatenate(((-1)*np.ones(Dataset_5.shape[0]),np.concatenate(((1)*np.ones(Dataset_6.shape[0]),np.concatenate(((-1)*np.ones(Dataset_7.shape[0]),np.concatenate(((-1)*np.ones(Dataset_8.shape[0]),(-1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGIT 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:10,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:10,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:10,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:10,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:10,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:10,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:100,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:10,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:10,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 1, Sigma: 10, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 10, Sigma: 10, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 1, Accuracy: 0.6491228070175439\n",
      "C: 100, Sigma: 10, Accuracy: 0.6491228070175439\n"
     ]
    }
   ],
   "source": [
    "Y_7 = np.array([np.concatenate(((-1)*np.ones(Dataset_0.shape[0]),np.concatenate(((-1)*np.ones(Dataset_1.shape[0]),np.concatenate(((-1)*np.ones(Dataset_2.shape[0]),np.concatenate(((-1)*np.ones(Dataset_3.shape[0]),np.concatenate(((-1)*np.ones(Dataset_4.shape[0]),np.concatenate(((-1)*np.ones(Dataset_5.shape[0]),np.concatenate(((-1)*np.ones(Dataset_6.shape[0]),np.concatenate(((1)*np.ones(Dataset_7.shape[0]),np.concatenate(((-1)*np.ones(Dataset_8.shape[0]),(-1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGIT 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:10,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:10,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:10,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:10,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:10,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:10,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:10,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:100,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:10,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.45614035087719296\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.45614035087719296\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.45614035087719296\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.45614035087719296\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.45614035087719296\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.45614035087719296\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.45614035087719296\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.45614035087719296\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.45614035087719296\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.45614035087719296\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.45614035087719296\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.45614035087719296\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.45614035087719296\n",
      "C: 1, Sigma: 1, Accuracy: 0.45614035087719296\n",
      "C: 1, Sigma: 10, Accuracy: 0.45614035087719296\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.45614035087719296\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.45614035087719296\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.45614035087719296\n",
      "C: 10, Sigma: 1, Accuracy: 0.45614035087719296\n",
      "C: 10, Sigma: 10, Accuracy: 0.45614035087719296\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.45614035087719296\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.45614035087719296\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.45614035087719296\n",
      "C: 100, Sigma: 1, Accuracy: 0.45614035087719296\n",
      "C: 100, Sigma: 10, Accuracy: 0.45614035087719296\n"
     ]
    }
   ],
   "source": [
    "Y_8 = np.array([np.concatenate(((-1)*np.ones(Dataset_0.shape[0]),np.concatenate(((-1)*np.ones(Dataset_1.shape[0]),np.concatenate(((-1)*np.ones(Dataset_2.shape[0]),np.concatenate(((-1)*np.ones(Dataset_3.shape[0]),np.concatenate(((-1)*np.ones(Dataset_4.shape[0]),np.concatenate(((-1)*np.ones(Dataset_5.shape[0]),np.concatenate(((-1)*np.ones(Dataset_6.shape[0]),np.concatenate(((-1)*np.ones(Dataset_7.shape[0]),np.concatenate(((1)*np.ones(Dataset_8.shape[0]),(-1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGIT 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_0 = (pd.read_excel('Data.xlsx', sheet_name=0).to_numpy())[:10,:]\n",
    "Dataset_1 = (pd.read_excel('Data.xlsx', sheet_name=1).to_numpy())[:10,:]\n",
    "Dataset_2 = (pd.read_excel('Data.xlsx', sheet_name=2).to_numpy())[:10,:]\n",
    "Dataset_3 = (pd.read_excel('Data.xlsx', sheet_name=3).to_numpy())[:10,:]\n",
    "Dataset_4 = (pd.read_excel('Data.xlsx', sheet_name=4).to_numpy())[:10,:]\n",
    "Dataset_5 = (pd.read_excel('Data.xlsx', sheet_name=5).to_numpy())[:10,:]\n",
    "Dataset_6 = (pd.read_excel('Data.xlsx', sheet_name=6).to_numpy())[:10,:]\n",
    "Dataset_7 = (pd.read_excel('Data.xlsx', sheet_name=7).to_numpy())[:10,:]\n",
    "Dataset_8 = (pd.read_excel('Data.xlsx', sheet_name=8).to_numpy())[:10,:]\n",
    "Dataset_9 = (pd.read_excel('Data.xlsx', sheet_name=9).to_numpy())[:100,:]\n",
    "\n",
    "Dataset = np.concatenate((Dataset_0,np.concatenate((Dataset_1,np.concatenate((Dataset_2,np.concatenate((Dataset_3,np.concatenate((Dataset_4,np.concatenate((Dataset_5,np.concatenate((Dataset_6,np.concatenate((Dataset_7,np.concatenate((Dataset_8,Dataset_9),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01, Sigma: 0.001, Accuracy: 0.6140350877192983\n",
      "C: 0.01, Sigma: 0.01, Accuracy: 0.6140350877192983\n",
      "C: 0.01, Sigma: 0.1, Accuracy: 0.6140350877192983\n",
      "C: 0.01, Sigma: 1, Accuracy: 0.6140350877192983\n",
      "C: 0.01, Sigma: 10, Accuracy: 0.6140350877192983\n",
      "C: 0.1, Sigma: 0.001, Accuracy: 0.6140350877192983\n",
      "C: 0.1, Sigma: 0.01, Accuracy: 0.6140350877192983\n",
      "C: 0.1, Sigma: 0.1, Accuracy: 0.6140350877192983\n",
      "C: 0.1, Sigma: 1, Accuracy: 0.6140350877192983\n",
      "C: 0.1, Sigma: 10, Accuracy: 0.6140350877192983\n",
      "C: 1, Sigma: 0.001, Accuracy: 0.6140350877192983\n",
      "C: 1, Sigma: 0.01, Accuracy: 0.6140350877192983\n",
      "C: 1, Sigma: 0.1, Accuracy: 0.6140350877192983\n",
      "C: 1, Sigma: 1, Accuracy: 0.6140350877192983\n",
      "C: 1, Sigma: 10, Accuracy: 0.6140350877192983\n",
      "C: 10, Sigma: 0.001, Accuracy: 0.6140350877192983\n",
      "C: 10, Sigma: 0.01, Accuracy: 0.6140350877192983\n",
      "C: 10, Sigma: 0.1, Accuracy: 0.6140350877192983\n",
      "C: 10, Sigma: 1, Accuracy: 0.6140350877192983\n",
      "C: 10, Sigma: 10, Accuracy: 0.6140350877192983\n",
      "C: 100, Sigma: 0.001, Accuracy: 0.6140350877192983\n",
      "C: 100, Sigma: 0.01, Accuracy: 0.6140350877192983\n",
      "C: 100, Sigma: 0.1, Accuracy: 0.6140350877192983\n",
      "C: 100, Sigma: 1, Accuracy: 0.6140350877192983\n",
      "C: 100, Sigma: 10, Accuracy: 0.6140350877192983\n"
     ]
    }
   ],
   "source": [
    "Y_9 = np.array([np.concatenate(((-1)*np.ones(Dataset_0.shape[0]),np.concatenate(((-1)*np.ones(Dataset_1.shape[0]),np.concatenate(((-1)*np.ones(Dataset_2.shape[0]),np.concatenate(((-1)*np.ones(Dataset_3.shape[0]),np.concatenate(((-1)*np.ones(Dataset_4.shape[0]),np.concatenate(((-1)*np.ones(Dataset_5.shape[0]),np.concatenate(((-1)*np.ones(Dataset_6.shape[0]),np.concatenate(((-1)*np.ones(Dataset_7.shape[0]),np.concatenate(((-1)*np.ones(Dataset_8.shape[0]),(1)*np.ones(Dataset_9.shape[0])))))))))))))))))))]).transpose()\n",
    "\n",
    "C = [0.01,0.1,1,10,100]                             \n",
    "Sigma = [0.001,0.01,0.1,1,10]\n",
    "\n",
    "for c in C:\n",
    "    for s in Sigma:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(Dataset[:,1:],Y_0,test_size=0.3, random_state=364)\n",
    "\n",
    "        Alpha = SVMPara(X_train,Y_train,c,X_train.shape[0],s)\n",
    "        w = Weight(Alpha,X_train,Y_train)\n",
    "\n",
    "        X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)\n",
    "        y = np.sign(X_test@w)\n",
    "        Acc = np.trace(confusion_matrix(Y_test,y))/len(Y_test)\n",
    "        print(f\"C: {c}, Sigma: {s}, Accuracy: {Acc}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bf79c014e16b3915abe4f16bab128ee50c3055dfd2d474fcf703de72c83e33a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
